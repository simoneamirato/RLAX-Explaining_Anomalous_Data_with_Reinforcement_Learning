{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11960515,"sourceType":"datasetVersion","datasetId":7520627},{"sourceId":11968339,"sourceType":"datasetVersion","datasetId":7525878},{"sourceId":12078969,"sourceType":"datasetVersion","datasetId":7603718},{"sourceId":12329697,"sourceType":"datasetVersion","datasetId":7772265}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q pyod","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T13:23:31.306925Z","iopub.execute_input":"2025-06-03T13:23:31.307123Z","iopub.status.idle":"2025-06-03T13:23:35.584164Z","shell.execute_reply.started":"2025-06-03T13:23:31.307105Z","shell.execute_reply":"2025-06-03T13:23:35.583232Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from stable_baselines3.common.distributions import CategoricalDistribution, SelfCategoricalDistribution\n# from stable_baselines3.common.type_aliases import PyTorchObs\nfrom typing import Optional\n\n# from generator import generate_dataset\n# from env import Env_FS\nimport torch\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n# from generator import create_ODDS\nimport random\nimport os\n# from generator import generate_dataset\n# import env\nfrom sklearn.model_selection import train_test_split\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.env_util import make_vec_env\nimport torch\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.neighbors import NearestNeighbors\nfrom stable_baselines3.common.policies import ActorCriticPolicy\nfrom torch.distributions import Distribution, Categorical\nfrom functools import partial\nimport gymnasium as gym\nimport numpy as np\nfrom gymnasium import spaces\nimport random\nfrom sklearn.neighbors import NearestNeighbors\nimport time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T13:23:35.586398Z","iopub.execute_input":"2025-06-03T13:23:35.586800Z","iopub.status.idle":"2025-06-03T13:23:54.624527Z","shell.execute_reply.started":"2025-06-03T13:23:35.586768Z","shell.execute_reply":"2025-06-03T13:23:54.623781Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Env_FS(gym.Env):\n\n    def __init__(self, X, y, o_b, i_b, rho = 0.1, model = None, max_steps = None, gamma = 0.9, max_neg_iter = 3):\n\n        super(Env_FS, self).__init__()\n\n        self.gamma= gamma\n        self.max_neg_iter = max_neg_iter\n\n        self.X = X\n        self.y = y\n        self.rho = rho\n        self.n_features = X.shape[1]\n        if max_steps is None:\n            self.max_steps = min(self.n_features, 30)\n        else:\n            self.max_steps = max_steps\n        self.o_b = o_b\n        self.i_b = i_b\n        self.model = model\n\n        self.action_space = spaces.Discrete(self.n_features)\n        self.observation_space = spaces.Box(low=0, high=1, shape=(self.n_features,), dtype=np.int8)\n\n        self.state = None\n        self.visited = set()\n        self.selected = None\n\n        self.AOR = np.zeros((2, self.n_features))\n        self.MDR = np.zeros((2, self.n_features))\n\n        self.call_to_step = 0\n        self.episode_number = 0\n        self.neg_reward_count = 0\n        self.time_step = 0\n\n    def seed(self, seed=None):\n        np.random.seed(seed)\n        return [seed]\n\n    def step(self, action):\n        self.call_to_step = self.call_to_step + 1\n\n        action = int(action)\n\n        if self.state[action] == 1:\n            return self.state.copy(), -10.0, False, False, {}\n\n        obs_tensor = torch.tensor(self.state, dtype=torch.float32).unsqueeze(0).to(self.model.device)\n\n        with torch.no_grad():\n            value_t = self.model.policy.predict_values(obs_tensor).cpu().item()\n\n        if len(self.selected)!=0:\n            score_cur = self.evaluation_subspace(self.selected, rho=self.rho)\n        else:\n            score_cur = 0\n        #state_prec = self.state.copy()\n        self.selected.append(action)\n        self.state[action] = 1 \n\n        score_suc = self.evaluation_subspace_wo_rho(self.selected, rho=self.rho)\n\n        reward = score_suc - score_cur\n\n        obs_tensor = torch.tensor(self.state, dtype=torch.float32).unsqueeze(0).to(self.model.device)\n\n        with torch.no_grad():\n            value_t1 = self.model.policy.predict_values(obs_tensor).cpu().item()\n        \n        if not hasattr(self, 'time_step'):\n            self.time_step = 0\n        \n        #if self.call_to_step >= 5000:\n        self.AOR[0, action] += 1\n        self.MDR[0, action] += 1\n        #######\n        #AOR\n        #\n        self.AOR[1, action] = self.AOR[1, action] + (value_t - value_t1)\n        #\n        #\n        \n        #MDR\n        #\n        self.MDR[1, action] = self.MDR[1, action] + (self.gamma**self.time_step * reward)\n        #\n        #\n        \n        #####\n        # self.AOR[1, action] = self.AOR[1, action] + (reward)\n\n\n        self.time_step += 1\n\n        if reward<0:\n            self.neg_reward_count +=1\n        else:              \n            self.neg_reward_count = 0\n        \n        #if self.call_to_step > 5000 and self.call_to_step % 1000 == 0:\n        if self.call_to_step % 1000 == 0:\n            print(f'{self.call_to_step:.0f}:')\n            for f in range(1,self.n_features):\n                aor_count = self.AOR[0,f]\n                aor_value = self.AOR[1,f]\n                mdr_count = self.MDR[0,f]\n                mdr_value = self.MDR[1,f]\n                if aor_count>0:\n                    aor_value /= aor_count\n                if mdr_count>0:\n                    mdr_value /= mdr_count\n                #print(f'[{f:.0f}:{aor_count:.0f}:{aor_value:.3f}]', end='')\n            if self.call_to_step > 500:\n                print(f'mean episode length = {self.call_to_step/self.episode_number:.1f}\\n')\n\n\n        \n        # print(f\"\\rF[0] = {self.AOR[0,0]:5f} - {self.AOR[1,0]:.5f}\", end=\"\")\n        # s=\"\\033[F\"\n        # for f in range(1,self.n_features):\n        #     print(f\"\\nF[{f}] = {self.AOR[0,f]:5f} - {self.AOR[1,f]:.5f}\", end=\"\")\n        #     s = s + \"\\033[F\"\n        # print(f\"{s}\", end=\"\"))\n            \n        \n        done = len(self.selected) >= self.max_steps\n\n        done = done or self.neg_reward_count >= self.max_neg_iter\n\n        if done:\n            self.episode_number += 1\n        \n        # print(f\"Step {len(self.selected)} - Action {action}, Reward {reward:.4f}, V(s): {value_t:.4f} → V(s’): {value_t1:.4f}\")\n\n        return self.state.copy(), reward, done, done, {}\n        #return self.state.copy(), reward, done, {}\n\n    \n\n    def reset(self, seed=None):\n        self.neg_reward_counter = 0\n        self.time_step = 0\n        self.selected = []\n        self.state = np.zeros(self.n_features, dtype=np.int8)\n        return self.state, {}\n\n    def outlier_scores(self, features, k=50):\n        features = np.array(features, dtype=int)\n\n        X_fit = self.X[self.y == 0][:, features]\n        if X_fit.ndim == 1:\n            X_fit = X_fit.reshape(-1, 1)\n\n        nbrs = NearestNeighbors(n_neighbors=k + 1, algorithm='auto').fit(X_fit)\n\n        X_ob = self.X[self.o_b][:, features]\n        if X_ob.ndim == 1:\n            X_ob = X_ob.reshape(-1, 1)\n\n        X_ib = self.X[self.i_b][:, features]\n        if X_ib.ndim == 1:\n            X_ib = X_ib.reshape(-1, 1)\n        \n        distances_o, _ = nbrs.kneighbors(X_ob)\n        distances_i, _ = nbrs.kneighbors(X_ib)\n\n        mean_distances_o = distances_o[:, 1:].mean(axis=1)\n        mean_distances_i = distances_i[:, 1:].mean(axis=1)\n\n        mean_distances_o = mean_distances_o/np.sqrt(features.shape[0])\n        mean_distances_i = mean_distances_i/np.sqrt(features.shape[0])\n\n        return mean_distances_o, mean_distances_i\n\n\n    def evaluation_subspace(self, features, rho):\n\n        rho_frac = rho * self.o_b.shape[0]\n        rho_frac = int(rho_frac)\n\n        o_os,i_os  = self.outlier_scores(features=features)\n\n        o_os_sorted = np.argsort(o_os)\n        rho_ids = o_os_sorted[:rho_frac+1]\n\n        sc_o_b = np.mean(o_os[rho_ids])\n        sc_i = np.mean(i_os)\n\n        max_i_os = np.max(i_os)\n        min_o_os = o_os[o_os_sorted[rho_frac]]\n\n        ss = 0\n        if (sc_o_b > sc_i) and (min_o_os > max_i_os):\n            ss = np.mean(o_os) - sc_i\n\n        return ss\n\n    def evaluation_subspace_wo_rho(self, features, rho):\n\n        o_os,i_os  = self.outlier_scores(features=features)\n\n        o_os_sorted = np.argsort(o_os)\n        sc_i = np.mean(i_os)\n\n        max_i_os = np.max(i_os)\n\n        ss = np.mean(o_os) - sc_i\n\n        return ss\n\n    def get_aor_scores(self):\n        self.MDR[0, self.MDR[0,:]==0] = 1\n        self.MDR[1, :]=self.MDR[1,:]/self.MDR[0,:]\n        self.AOR[0, self.AOR[0,:]==0] = 1\n        self.AOR[1, :]=self.AOR[1,:]/self.AOR[0,:]\n        ranking_AOR = np.argsort(self.AOR[1, :])[::-1]\n        ranking_MDR = np.argsort(self.MDR[1,:])[::-1]\n        return ranking_AOR, self.AOR[1, ranking_AOR], ranking_MDR, self.MDR[1, ranking_MDR]\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-03T13:23:54.625390Z","iopub.execute_input":"2025-06-03T13:23:54.625893Z","iopub.status.idle":"2025-06-03T13:23:54.643877Z","shell.execute_reply.started":"2025-06-03T13:23:54.625873Z","shell.execute_reply":"2025-06-03T13:23:54.643157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom scipy.io import loadmat\nimport os\nfrom pyod.utils.utility import standardizer\nimport numpy.random\n\ndef generate_dataset(n_inliers=100, n_outliers=20, n_features=15, n_informative=7, radius = 5, seed=42):\n    np.random.seed(seed)\n\n    n_noise = n_features - n_informative\n\n    #Inliers\n    informative_inliers = np.random.normal(loc=0.0, scale=1.0, size=(n_inliers, n_informative))\n    noise_inliers = np.random.normal(loc=0.0, scale=1.0, size=(n_inliers, n_noise))\n    X_inliers = np.hstack([informative_inliers, noise_inliers])\n    y_inliers = np.zeros(n_inliers)\n\n    #Outliers\n    '''informative_outliers = np.random.normal(loc=3.0, scale=7.0, size=(n_outliers, n_informative))\n    noise_outliers = np.random.normal(loc=0.0, scale=1.0, size=(n_outliers, n_noise))\n    X_outliers = np.hstack([informative_outliers, noise_outliers])\n    y_outliers = np.ones(n_outliers)'''\n\n    informative_outliers = []\n    while len(informative_outliers) < n_outliers:\n        candidate = np.random.uniform(low=-5, high=5, size=n_informative)\n        if np.linalg.norm(candidate) > radius:\n            informative_outliers.append(candidate)\n    informative_outliers = np.array(informative_outliers)\n\n    noise_outliers = np.random.normal(loc=0.0, scale=1.0, size=(n_outliers, n_noise))\n    X_outliers = np.hstack([informative_outliers, noise_outliers])\n    y_outliers = np.ones(n_outliers)\n\n    X = np.vstack([X_inliers, X_outliers])\n    y = np.concatenate([y_inliers, y_outliers])\n    X, y = shuffle(X, y, random_state=seed)\n\n    true_feature_importance = np.zeros(n_features)\n    true_feature_importance[:n_informative] = 1\n\n    perm = np.random.permutation(X.shape[1])\n\n    X = X[:, perm]\n    true_feature_importance = true_feature_importance[perm]\n\n    return X, y, true_feature_importance.astype(int)\n\n\n\ndef create_ODDS(dataset, seed):\n    np.random.seed(seed)\n    mat = loadmat(os.path.join('/kaggle/input/train-sets/trainsets', dataset))\n\n    X = mat['X']\n    y = mat['y'].ravel()\n    X = standardizer(X)\n\n    outliers_fraction = np.count_nonzero(y) / len(y)\n    outliers_percentage = round(outliers_fraction * 100, ndigits=4)\n    ids_anomalies = np.where(y == 1)[0]\n\n    return X, y, ids_anomalies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T13:23:54.644832Z","iopub.execute_input":"2025-06-03T13:23:54.645412Z","iopub.status.idle":"2025-06-03T13:23:55.814153Z","shell.execute_reply.started":"2025-06-03T13:23:54.645388Z","shell.execute_reply":"2025-06-03T13:23:55.813612Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nclass OutDistribution(CategoricalDistribution):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n\n    def proba_distribution(self: SelfCategoricalDistribution, action_logits: torch.Tensor, obs) -> SelfCategoricalDistribution:\n\n        \n        #print(f'action_logits in [{torch.min(action_logits)},{torch.max(action_logits)}]')\n        #print(f'action_logits = {action_logits} --- obs = {obs}')\n\n        #print(action_logits.logsumexp(dim=-1, keepdim=True))\n        \n        action_logits[obs == 1] = -float('inf')        \n\n        #print(action_logits.logsumexp(dim=-1, keepdim=True))\n\n        \n        self.distribution = Categorical(logits=action_logits)\n\n        #print(f'probs = {self.distribution.probs} -- obs = {obs}')\n\n        \n        return self\n\n\nclass OutPolicy(ActorCriticPolicy):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        dist_kwargs = self.dist_kwargs\n        if dist_kwargs is None:\n            dist_kwargs = {}\n        self.action_dist = OutDistribution(int(self.action_space.n), **dist_kwargs)\n\n\n    \n    def _get_action_dist_from_latent(self, latent_pi: torch.Tensor) -> Distribution:\n        raise ValueError(\"Perché mi hai chiamato?\")\n\n\n    \n    def _get_action_dist_from_latent(self, obs, latent_pi: torch.Tensor) -> Distribution:\n        \"\"\"\n        Retrieve action distribution given the latent codes.\n        :param latent_pi: Latent code for the actor\n        :return: Action distribution\n        \"\"\"\n        mean_actions = self.action_net(latent_pi)\n\n        #########print(f'mean_actions = {mean_actions}')\n\n        return self.action_dist.proba_distribution(action_logits=mean_actions, obs=obs)\n\n\n    def my_get_actions(self, distribution, obs):\n        \n        probs = distribution.distribution.probs[0].cpu().clone()\n        #probs = torch.exp(distribution.distribution.logits)\n        \n        probs = probs / torch.sum(probs)\n        \n        legal_actions = torch.where(obs[0].cpu() != 1)[0]\n        \n        cumprobs = torch.cumsum(probs[legal_actions], dim = 0)\n        rnd = np.random.rand()\n        \n        pos = torch.searchsorted(cumprobs, rnd, right = True) - 1\n        #pos = bisect.bisect_right(cumprobs, rnd) - 1\n        \n        action = torch.tensor(legal_actions[pos]).clone().detach().to('cuda')\n        #action = torch.tensor(legal_actions[pos].clone().detach().to('cuda'))\n        log_prob = torch.exp(distribution.distribution.logits[0][action]).detach().to('cuda')\n        return action, log_prob\n    \n\n    \n    def forward(self, obs: torch.Tensor, deterministic: bool = False) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Forward pass in all the networks (actor and critic)\n\n        :param obs: Observation\n        :param deterministic: Whether to sample or use deterministic actions\n        :return: action, value and log probability of the action\n        \"\"\"\n        # Preprocess the observation if needed\n        features = self.extract_features(obs)\n\n        if self.share_features_extractor:\n            latent_pi, latent_vf = self.mlp_extractor(features)\n        else:\n            pi_features, vf_features = features\n            latent_pi = self.mlp_extractor.forward_actor(pi_features)\n            latent_vf = self.mlp_extractor.forward_critic(vf_features)\n        # Evaluate the values for the given observations\n        values = self.value_net(latent_vf)\n        distribution = self._get_action_dist_from_latent(obs,latent_pi)\n        actions = distribution.get_actions(deterministic=deterministic)\n        log_prob = distribution.log_prob(actions)\n        \n        actions = actions.reshape((-1, *self.action_space.shape))  # type: ignore[misc]\n        return actions, values, log_prob\n\n\n    def q_function(self, obs: torch.Tensor):\n        features = self.extract_features(obs)\n        if self.share_features_extractor:\n            latent_pi, latent_vf = self.mlp_extractor(features)\n        else:\n            pi_features, vf_features = features\n            latent_pi = self.mlp_extractor.forward_actor(pi_features)\n            latent_vf = self.mlp_extractor.forward_critic(vf_features)\n        values = self.value_net(latent_vf)\n        \n        mean_actions = self.action_net(latent_pi)\n        distribution = Categorical(logits=mean_actions)\n        \n        return distribution.probs\n\n\n\n\n    \n    def evaluate_actions(self, obs: torch.Tensor, actions: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]:\n        \"\"\"\n        Evaluate actions according to the current policy,\n        given the observations.\n\n        :param obs: Observation\n        :param actions: Actions\n        :return: estimated value, log likelihood of taking those actions\n            and entropy of the action distribution.\n        \"\"\"\n        # Preprocess the observation if needed\n        features = self.extract_features(obs)\n        if self.share_features_extractor:\n            latent_pi, latent_vf = self.mlp_extractor(features)\n        else:\n            pi_features, vf_features = features\n            latent_pi = self.mlp_extractor.forward_actor(pi_features)\n            latent_vf = self.mlp_extractor.forward_critic(vf_features)\n        distribution = self._get_action_dist_from_latent(obs, latent_pi)\n        log_prob = distribution.log_prob(actions)\n        values = self.value_net(latent_vf)\n        entropy = distribution.entropy()\n        return values, log_prob, entropy\n\n    def get_distribution(self, obs: torch.Tensor) -> Distribution:\n        \"\"\"\n        Get the current policy distribution given the observations.\n\n        :param obs:\n        :return: the action distribution.\n        \"\"\"\n        features = super().extract_features(obs, self.pi_features_extractor)\n        latent_pi = self.mlp_extractor.forward_actor(features)\n        return self._get_action_dist_from_latent(obs, latent_pi)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T13:23:55.814973Z","iopub.execute_input":"2025-06-03T13:23:55.815189Z","iopub.status.idle":"2025-06-03T13:23:55.828834Z","shell.execute_reply.started":"2025-06-03T13:23:55.815173Z","shell.execute_reply":"2025-06-03T13:23:55.828181Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test_outlier_scores(X_train,y_train,X_test,y_test,features,k=50):\n    \n    features = np.array(features, dtype=int)\n    X_tr = X_train[y_train==0][:, features]\n    if X_tr.ndim == 1:\n            X_tr = X_tr.reshape(-1, 1)\n    nbrs = NearestNeighbors(n_neighbors=k + 1, algorithm='auto').fit(X_tr)\n\n    X_te = X_test[:, features]\n    if X_te.ndim == 1:\n            X_te = X_te.reshape(-1, 1)\n    distances, _ = nbrs.kneighbors(X_te)\n\n    mean_distances = distances.mean(axis=1)\n    mean_distances = mean_distances/np.sqrt(features.shape[0])\n        \n    return mean_distances","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T13:23:55.829619Z","iopub.execute_input":"2025-06-03T13:23:55.829916Z","iopub.status.idle":"2025-06-03T13:23:55.855308Z","shell.execute_reply.started":"2025-06-03T13:23:55.829890Z","shell.execute_reply":"2025-06-03T13:23:55.854652Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_ss(X_train,y_train,features, o_b):\n\n    X_ob = X_train[o_b]\n    y_ob = y_train[o_b]\n    scores = test_outlier_scores(X_train,y_train,X_ob,y_ob,features)\n    sc_o_b = np.mean(scores)\n\n    return sc_o_b","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T13:23:55.857622Z","iopub.execute_input":"2025-06-03T13:23:55.857839Z","iopub.status.idle":"2025-06-03T13:23:55.873241Z","shell.execute_reply.started":"2025-06-03T13:23:55.857824Z","shell.execute_reply":"2025-06-03T13:23:55.872599Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_ranking_scores(model, X_train, y_train, X_test, y_test, ranking, o_b = None, score_types=[\"q_auc\", \"v_aor\"], rho=0.1, k=50):\n    \n    d = min(5000, len(ranking))\n    #d = len(ranking)\n    obs = np.zeros((1, d))\n    obs_tensor = torch.tensor(obs.copy()).to('cuda')\n\n    results = {}\n\n    if 'v_aor' in score_types or 'q_aor' in score_types:\n        V_f = np.zeros(d)\n        Q_f = np.zeros((d, d))\n\n        for i in range(d):\n            ids = ranking[:i+1]\n            obs[0] = 0\n            obs[0, ids] = 1\n            obs_tensor = torch.tensor(obs.copy()).to('cuda')\n\n            V_f[i] = model.policy.predict_values(obs_tensor).item()\n\n            if i < d - 1:\n                Q_f[i, :] = model.policy.q_function(obs_tensor)[0].detach().cpu().numpy()\n\n        if 'v_aor' in score_types:\n            results['v_aor'] = V_f\n        if 'q_aor' in score_types:\n            results['q_aor'] = Q_f\n\n    if 'auc' in score_types:\n        auc_curve = np.zeros(d)\n        for i in range(d):\n            selected = ranking[:i+1]\n            scores_out = test_outlier_scores(X_train, y_train, X_test, y_test, selected, k=k)\n            auc_curve[i] = roc_auc_score(y_test, scores_out)\n        results['auc'] = auc_curve\n\n    if \"q_ranking\" in score_types or \"q_auc\" in score_types:\n        \n        greedy_ranking = np.zeros(d, dtype=np.int32)\n        obs = np.zeros((1, d))\n        obs_tensor = torch.tensor(obs.copy()).to('cuda')\n        probs = model.policy.q_function(obs_tensor)[0].detach().cpu().numpy()\n        greedy_ranking[0] = np.argmax(probs)\n\n        for i in range(d - 1):\n            obs[0] = 0\n            ids = greedy_ranking[:i+1]\n            obs[0, ids] = 1\n            obs_tensor = torch.tensor(obs.copy()).to('cuda')\n            probs = model.policy.q_function(obs_tensor)[0].detach().cpu().numpy()\n            probs[obs[0] == 1] = -1\n            greedy_ranking[i+1] = np.argmax(probs)\n\n        results['q_ranking'] = greedy_ranking\n\n        if \"q_auc\" in score_types:\n            auc_greedy = np.zeros(d)\n            for i in range(d):\n                selected = greedy_ranking[:i+1]\n                scores_out = test_outlier_scores(X_train, y_train, X_test, y_test, selected, k=k)\n                auc_greedy[i] = roc_auc_score(y_test, scores_out)\n            results['q_auc'] = auc_greedy\n\n    if \"subspace\" in score_types:\n        ss_s = np.zeros(d)\n        for i in range(d):\n            ss = evaluate_ss(X_train,y_train,ranking[:i+1], o_b)\n            ss_s[i] = ss\n\n        results['subspace'] = ss_s\n\n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T13:23:55.873874Z","iopub.execute_input":"2025-06-03T13:23:55.874110Z","iopub.status.idle":"2025-06-03T13:23:55.886129Z","shell.execute_reply.started":"2025-06-03T13:23:55.874087Z","shell.execute_reply":"2025-06-03T13:23:55.885463Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_fs_analysis(aor_scores_train, auc_train, V_f, V_auc, aor_count_train, ss_s, r, steps, dataset_name=\"\"):\n    d = len(aor_scores_train)\n    pos = np.arange(d)\n\n    # --- AOR plot ---\n    plt.figure()\n    plt.plot(pos, aor_scores_train)\n    plt.grid()\n    plt.xlabel('Feature ranking')\n    plt.ylabel('AOR')\n    plt.title(f'Average Of Rewards {dataset_name}')\n    plt.savefig(f'AOR_{dataset_name}_{r}_{steps}.png')\n\n    # --- AUC Train plot ---\n    auc = auc_train\n    a_dim = np.argmax(auc)\n    a_auc = auc[a_dim]\n    a_dim += 1\n    alpha0 = 0.5\n    alpha = alpha0 / d\n    quality = auc - alpha * pos\n    q_dim = np.argmax(quality)\n    q_auc = auc[q_dim]\n    q_dim += 1\n    ss_dim = np.argmax(ss_s)\n\n    plt.figure()\n    plt.axis([0, d, np.min(auc), np.max(auc) * 1.025])\n    plt.plot(pos, auc, 'b-', label=f'AUC ({a_dim},{a_auc:.3f})')\n    plt.plot(pos, quality, 'r--', label=f'Quality ({q_dim},{q_auc:.3f})')\n    plt.plot(pos, V_auc, 'g-', label='AUC_V')\n    plt.plot(q_dim-1, q_auc, 'ro', label=\"Best Quality\")\n    plt.plot(a_dim-1, a_auc, 'b^', label=\"Best AUC\")\n    plt.legend(loc='lower right')\n    plt.grid()\n    plt.xlabel('Feature ranking')\n    plt.title(f'AUC & Quality: Training set {dataset_name}')\n\n    print(f'[Train] Best AUC at dim={a_dim} ({a_dim/d*100:.2f}%), AUC = {a_auc:.5f}')\n    print(f'[Train] Best Quality at dim={q_dim} ({q_dim/d*100:.2f}%), AUC = {q_auc:.5f}')\n    plt.savefig(f'quality_train_{dataset_name}_{r}_{steps}.png')\n    # --- AUC Test plot ---\n    # auc = auc_test\n    # a_dim = np.argmax(auc)\n    # a_auc = auc[a_dim]\n    # a_dim += 1\n    # quality = auc - alpha * pos\n    # q_dim = np.argmax(quality)\n    # q_auc = auc[q_dim]\n    # q_dim += 1\n\n    # plt.figure()\n    # plt.axis([0, d, np.min(auc), np.max(auc) * 1.025])\n    # plt.plot(pos, auc, 'b-', label=f'AUC ({a_dim},{a_auc:.3f})')\n    # plt.plot(pos, quality, 'r--', label=f'Quality ({q_dim},{q_auc:.3f})')\n    # plt.plot(pos, V_auc, 'g-', label='AUC_V')\n    # plt.plot(q_dim-1, q_auc, 'ro', label=\"Best Quality\")\n    # plt.plot(a_dim-1, a_auc, 'b^', label=\"Best AUC\")\n    # plt.legend(loc='lower right')\n    # plt.grid()\n    # plt.xlabel('Feature ranking')\n    # plt.title(f'AUC & Quality: Test set {dataset_name}')\n\n    # print(f'[Test] Best AUC at dim={a_dim} ({a_dim/d*100:.2f}%), AUC = {a_auc:.5f}')\n    # print(f'[Test] Best Quality at dim={q_dim} ({q_dim/d*100:.2f}%), AUC = {q_auc:.5f}')\n    # plt.savefig(f'quality_test_{dataset_name}_{r}_{steps}.png')\n    \n    # --- AOR count plot ---\n    plt.figure()\n    plt.plot(pos, aor_count_train)\n    plt.xlabel('Feature ranking')\n    plt.title(f'Feature count {dataset_name}')\n    plt.grid()\n    plt.savefig(f'AOR_count_{dataset_name}_{r}_{steps}.png')\n    \n    # --- Value function AOR plot ---\n    plt.figure()\n    plt.plot(pos, V_f)\n    plt.title(f'Value Function {dataset_name}')\n    plt.xlabel('Feature ranking')\n    #plt.ylabel('')\n    plt.grid()\n    plt.savefig(f'Value_f_{dataset_name}_{r}_{steps}.png')\n\n    # --- Subspace score plot ---\n    plt.figure()\n    plt.plot(pos, ss_s, label=f'SS ({ss_dim},{ss_s[ss_dim]:.3f})', color='m')\n    plt.title(f'Subspace score {dataset_name}')\n    plt.xlabel('Feature ranking')\n    plt.grid()\n    plt.legend(loc='lower right')\n    plt.savefig(f'Subspace_score_{dataset_name}_{r}_{steps}.png')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T13:23:55.886825Z","iopub.execute_input":"2025-06-03T13:23:55.887088Z","iopub.status.idle":"2025-06-03T13:23:55.902915Z","shell.execute_reply.started":"2025-06-03T13:23:55.887062Z","shell.execute_reply":"2025-06-03T13:23:55.902270Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def set_seed(seed=42):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\ndef make_env(rho=0.1, gamma=0.9, max_neg_iter=3):\n    env = Env_FS(X_train, y_train, new_o_indices, new_i_indices, rho=rho, gamma=gamma, max_neg_iter=max_neg_iter)\n    env_ref['env'] = env\n    return env","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T13:23:55.903639Z","iopub.execute_input":"2025-06-03T13:23:55.903867Z","iopub.status.idle":"2025-06-03T13:23:55.913278Z","shell.execute_reply.started":"2025-06-03T13:23:55.903852Z","shell.execute_reply":"2025-06-03T13:23:55.912526Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"real_ds = True\nhigh_dims = False\n\nif high_dims:\n    n_variant = 1\n    datasets = ['GSE13576']\nelse:\n    n_variant = 5\n    datasets = ['arrhythmia',\n            #'cardio',\n            #'ionosphere',\n            'letter',\n            #'mnist',\n            #'musk',\n            'optdigits',\n            #'pendigits',\n            #'pima',\n            # 'satellite',\n            # 'satimage-2',\n            #'shuttle',\n            #'vertebral',\n            #'vowels',\n            # 'wbc'\n               ]\n    #datasets = ['InternetAds']\n    datasets = ['Portmap']\n\n\n'''datasets = ['arrhythmia.mat',\n            #'cardio.mat',\n            #'ionosphere.mat',\n            #'letter.mat'\n           ]'''\n\n\nn_inliers = 500\nn_outliers = int(n_inliers * 0.10)\nn_features = 300\nn_informative = 5\n\nrho = 0.5\n\n#seed = np.random.randint(0xffffffff)\nseed = 2568117345\nprint(f\"SEED Generale: {seed}\")\nset_seed(seed)\n\n#\n#\nn_runs =1\n#\n#\n\ntime_steps = [50000]\n\ngammas = [0.99]\n# gamma = 0.95\nmax_neg_iter = 3\n\nseeds = np.random.randint(0, 0xffffffff, len(datasets) * n_variant * n_runs)\n\n#stats = []\n\nfor r in range(n_runs):\n    for id_d in range(len(datasets)):\n        for gamma in gammas:\n            for steps in time_steps:\n                for v in range(n_variant):\n                    id_seed = r * (len(datasets) * n_variant) + id_d * n_variant + v\n                    seed = int(seeds[id_seed])\n                    print(f\"\\033[1m***SEED run {r} dataset {id_d} = {seed}***\")\n                    \n                    set_seed(seed)\n        \n                    if real_ds:\n                        if high_dims:\n                            dataset = datasets[id_d]\n                            X = np.load(f'/kaggle/input/internetads/{dataset}_X.npy')\n                            y = np.load(f'/kaggle/input/internetads/{dataset}_y.npy')\n    \n                            o_indices_all = np.where(y == 1)[0]\n                            i_indices = np.where(y == 0)[0]\n                            if len(i_indices) > 10000:\n                                i_indices = np.random.choice(i_indices, size=10000, replace=False)\n                \n                            o_indices = np.random.choice(o_indices_all, size=min(20, len(o_indices_all)), replace=False)\n                \n                            selected_indices = np.concatenate([o_indices, i_indices])\n                \n                            X_train = X[selected_indices]\n                            y_train = y[selected_indices]\n                            new_o_indices = np.where(y_train == 1)[0]\n                            new_i_indices = np.where(y_train == 0)[0]\n    \n                            new_i_indices = np.random.choice(new_i_indices, size=min(20, len(new_i_indices)), replace=False)\n        \n                        else:\n                            dataset = f'{datasets[id_d]}_{v}'\n                            #X, y,_ = create_ODDS(dataset, seed = seed)\n                            # data = np.load(f'/kaggle/input/train-sets-odds/{dataset}.npz')\n                            data = np.load(f'/kaggle/input/portmap-03-11-v3/{dataset}.npz')\n                            X_train = data['X']\n                            y_train = data['y']\n    \n                            new_o_indices = np.where(y_train == 1)[0]\n                            new_i_indices = np.where(y_train == 0)[0]\n            \n                            y_train[y_train == -1] = 0\n                        \n                        print(f\"Using dataset {dataset}, dim: {X_train.shape[1]}, n_sample: {X_train.shape[0]}\")\n                    \n                    else:\n                        dataset = f\"synthetic_{n_inliers}_{n_outliers}\"\n                        X, y, important_mask = generate_dataset(n_inliers=n_inliers, n_outliers=n_outliers, n_features=n_features, n_informative=n_informative,seed=seed)\n                        print(f\"Using dataset {dataset} with mask {np.where(important_mask==1)[0]}\")\n        \n                        o_indices_all = np.where(y == 1)[0]\n                        i_indices = np.where(y == 0)[0]\n                        if len(i_indices) > 10000:\n                            i_indices = np.random.choice(i_indices, size=10000, replace=False)\n            \n                        o_indices = np.random.choice(o_indices_all, size=min(20, len(o_indices_all)), replace=False)\n            \n                        selected_indices = np.concatenate([o_indices, i_indices])\n            \n                        X_train = X[selected_indices]\n                        y_train = y[selected_indices]\n                        new_o_indices = np.where(y_train == 1)[0]\n                        new_i_indices = np.where(y_train == 0)[0]\n                        new_i_indices = np.random.choice(new_i_indices, size=min(20, len(new_i_indices)), replace=False)\n            \n                    env_ref = {}\n        \n                    #policy = OutPolicy()\n                    vec_env = make_vec_env(partial(make_env, rho=rho, gamma=gamma, max_neg_iter=max_neg_iter), n_envs=1)\n                    model = PPO(OutPolicy, vec_env, verbose=0, device='cuda', gamma=gamma)\n        \n                    env_ref['env'].model = model\n                    #start_time = time.time()\n                    model.learn(total_timesteps=steps, progress_bar=False)\n                    #end_time = time.time()\n        \n                    #duration = end_time - start_time\n                    #stats.append({\n                    #    'Dataset': dataset,\n                    #    'Samples': X_train.shape[0],\n                    #    'Features': X_train.shape[1],\n                    #    'Timesteps': steps,\n                    #    'Train Time (s)': duration\n                    #})\n        \n                    #print(stats)\n                    \n                    aor_ranking_train, aor_scores_train, mdr_ranking_train,mdr_scores_train = env_ref['env'].get_aor_scores()\n        \n        \n                    aor_count_train = env_ref['env'].AOR[0,:]\n                    aor_count_train = aor_count_train[aor_ranking_train]\n\n                    mdr_count_train = env_ref['env'].MDR[0,:]\n                    mdr_count_train = mdr_count_train[mdr_ranking_train]\n                    \n        \n                    model.save(f\"dir/FSwRL_{dataset}_{steps}_{r}_{gamma}\")\n        \n                    #out_ids = np.setdiff1d(o_indices_all, o_indices)\n                    #ids_X_test = np.concatenate([i_indices, out_ids])\n        \n                    #X_test = X[ids_X_test]\n                    #y_test = y[ids_X_test]\n        \n        \n                    aor_auc_train = np.zeros(min(5000,len(aor_ranking_train)))\n                    mdr_auc_train = np.zeros(min(5000,len(mdr_ranking_train)))\n                    #auc_test = np.zeros(ranking_train.shape)\n                    aor_subspace_scores = np.zeros(min(5000,len(aor_ranking_train)))\n                    mdr_subspace_scores = np.zeros(min(5000,len(mdr_ranking_train)))\n                    for i in range(min(5000,len(aor_ranking_train))):\n                        #scores_out = test_outlier_scores(X_train, y_train, X_test, y_test, ranking_train[:i+1], k=50)\n                        #auc_value = roc_auc_score(y_test, scores_out)\n                        #auc_test[i] = auc_value\n                        scores_out = test_outlier_scores(X_train, y_train, X_train, y_train, aor_ranking_train[:i+1], k=50)\n                        auc_value = roc_auc_score(y_train, scores_out)\n                        aor_auc_train[i] = auc_value\n                        ss = evaluate_ss(X_train,y_train, aor_ranking_train[:i+1], new_o_indices)\n                        aor_subspace_scores[i] = ss\n\n                        scores_out = test_outlier_scores(X_train, y_train, X_train, y_train, mdr_ranking_train[:i+1], k=50)\n                        auc_value = roc_auc_score(y_train, scores_out)\n                        mdr_auc_train[i] = auc_value\n                        ss = evaluate_ss(X_train,y_train,mdr_ranking_train[:i+1], new_o_indices)\n                        mdr_subspace_scores[i] = ss\n                        \n                    print('---AUC e SS calcolati---')\n                    results = compute_ranking_scores(model, X_train, y_train, X_train, y_train, aor_ranking_train, score_types = ['q_auc','v_aor'])\n                    #value_func = compute_ranking_scores(model, X_train, y_train, X_train, y_train, ranking_train, score_type = 'v_aor')\n                    print('---Altre misure calcolate---')\n                    #----PLOT-----\n                    # plot_fs_analysis(aor_scores_train, aor_auc_train, results['v_aor'], results['q_auc'], aor_count_train, aor_subspace_scores, r, steps, dataset_name=f\"{dataset}\")\n\n                    # plot_fs_analysis(mdr_scores_train, mdr_auc_train, results['v_aor'], mdr_count_train, mdr_subspace_scores, r, steps, dataset_name=f\"{dataset}\")\n                    #----Salvataggio risultati-----\n                    \n                    #np.save(f'auc_{dataset}_{steps}_{r}.npy', auc_test)\n                    np.save(f'aor_auc_train_{dataset}_{steps}_{gamma}_{r}.npy', aor_auc_train)\n                    np.save(f'mdr_auc_train_{dataset}_{steps}_{gamma}_{r}.npy', mdr_auc_train)\n                    np.save(f'AOR_subspace_scores_{dataset}_{steps}_{gamma}_{r}.npy', aor_subspace_scores)\n                    np.save(f'MDR_subspace_scores_{dataset}_{steps}_{gamma}_{r}.npy', mdr_subspace_scores)\n                    np.save(f'q_ranking_{dataset}_{steps}_{gamma}_{r}.npy', results['q_ranking'])\n                    np.save(f'q_auc_{dataset}_{steps}_{gamma}_{r}.npy', results['q_auc'])\n                    np.save(f'v_function_AOR_{dataset}_{steps}_{gamma}_{r}.npy', results['v_aor'])            \n                    np.save(f\"AOR_ranking_{dataset}_{steps}_{gamma}_{r}.npy\", aor_ranking_train)\n                    np.save(f\"AOR_{dataset}_{steps}_{gamma}_{r}.npy\", aor_scores_train)\n                    np.save(f\"count_{dataset}_{steps}_{gamma}_{r}.npy\", aor_count_train)\n                    np.save(f\"MDR_ranking_{dataset}_{steps}_{gamma}_{r}.npy\", mdr_ranking_train)\n                    np.save(f\"MDR_{dataset}_{steps}_{gamma}_{r}.npy\", mdr_scores_train)\n                    np.save(f\"MDR_count_{dataset}_{steps}_{gamma}_{r}.npy\", mdr_count_train)\n                    \n                    #print(f\"Max AUC ottenuto: {np.max(all_aucs):.4f} con {np.argmax(all_aucs)} feature\")\n                    print(f\"Ranking: {aor_ranking_train}\")\n                    print(f\"Ranking: {mdr_ranking_train}\")\n\n            \n\n            \n            ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T14:18:34.293191Z","iopub.execute_input":"2025-06-03T14:18:34.293806Z","iopub.status.idle":"2025-06-03T14:45:11.702695Z","shell.execute_reply.started":"2025-06-03T14:18:34.293782Z","shell.execute_reply":"2025-06-03T14:45:11.701494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# obs = np.zeros((1, ranking_train.shape[0]))\n\n# V_f = np.zeros(ranking_train.shape[0])\n# Q_f = np.zeros((ranking_train.shape[0],ranking_train.shape[0]))\n\n# for i in range(ranking_train.shape[0]):\n#     ids = ranking_train[:i+1]    \n#     obs[0, ids] = 1\n#     obs_tensor = torch.tensor(obs.copy()).to('cuda')\n#     V_f[i] = model.policy.predict_values(obs_tensor)\n#     if i < ranking_train.shape[0] - 1:\n#         Q_f[i,:] = model.policy.q_function(obs_tensor)[0].detach().cpu().numpy()\n\n\n# V_ranking_train = np.zeros(ranking_train.shape, dtype=np.int32)\n# obs = np.zeros((1, ranking_train.shape[0]))\n# probs = model.policy.q_function(obs_tensor)[0].detach().cpu().numpy()\n# V_ranking_train[0] = np.argmax(probs)\n# for i in range(len(V_ranking_train)-1):\n#     ids = V_ranking_train[:i+1]    \n#     obs[0, ids] = 1\n#     obs_tensor = torch.tensor(obs.copy()).to('cuda')\n#     probs = model.policy.q_function(obs_tensor)[0].detach().cpu().numpy()\n#     #print(i,probs)\n#     probs[obs[0] == 1] = -1\n#     V_ranking_train[i+1] = np.argmax(probs)\n\n\n# V_auc = np.zeros(V_ranking_train.shape)\n\n# for i in range(len(V_ranking_train)):\n#     scores_out = test_outlier_scores(X_train, y_train, X_test, y_test, V_ranking_train[:i+1], k=50)\n#     auc_value = roc_auc_score(y_test, scores_out)\n#     V_auc[i] = auc_value\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T13:29:18.007260Z","iopub.execute_input":"2025-06-03T13:29:18.007902Z","iopub.status.idle":"2025-06-03T13:29:18.012013Z","shell.execute_reply.started":"2025-06-03T13:29:18.007863Z","shell.execute_reply":"2025-06-03T13:29:18.011275Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ranking_train_tensor = torch.tensor(ranking_train.reshape((1,ranking_train.shape[0])).copy())\n# ranking_train_tensor = ranking_train_tensor.to('cuda')\n\n# obs = np.zeros((1, ranking_train.shape[0]))\n\n# i = 1\n\n# ss_s = np.zeros(ranking_train.shape[0])\n\n# for i in range(ranking_train.shape[0]):\n#     ss = evaluate_ss(X_train,y_train,X_test,y_test,ranking_train[:i+1], new_o_indices)\n#     ss_s[i] = ss\n#     #print(f'Score sottospazio di dim {i}: {ss}')\n#     ids = ranking_train[:i+1]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T13:29:18.012747Z","iopub.execute_input":"2025-06-03T13:29:18.013030Z","iopub.status.idle":"2025-06-03T13:29:18.025341Z","shell.execute_reply.started":"2025-06-03T13:29:18.013008Z","shell.execute_reply":"2025-06-03T13:29:18.024712Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"arrhythmia.mat: (452, 274), n_an: 66\ncardio.mat: (1831, 21), n_an: 176\nglass.mat: (214, 9), n_an: 9\nionosphere.mat: (351, 33), n_an: 126\nletter.mat: (1600, 32), n_an: 100\nlympho.mat: (148, 18), n_an: 6\nmnist.mat: (7603, 100), n_an: 700\nmusk.mat: (3062, 166), n_an: 97\noptdigits.mat: (5216, 64), n_an: 150\npendigits.mat: (6870, 16), n_an: 156\npima.mat: (768, 8), n_an: 268\nsatellite.mat: (6435, 36), n_an: 2036\nsatimage-2.mat: (5803, 36), n_an: 71\nshuttle.mat: (49097, 9), n_an: 3511\nvertebral.mat: (240, 6), n_an: 30\nvowels.mat: (1456, 12), n_an: 50\nwbc.mat: (378, 30), n_an: 21","metadata":{}},{"cell_type":"code","source":"# import numpy as np\n# import matplotlib.pyplot as plt\n\n# #\n# #\n# #\n\n# aor_scores_train = np.load('/kaggle/working/ranking_arrhythmia.mat_train_ob20_normalized_20000_0.npy')\n# auc_train = np.load('/kaggle/working/auc_curve_train_arrhythmia.mat_20000_0.npy')\n# auc_test = np.load('/kaggle/working/auc_curve_arrhythmia.mat_20000_0.npy')\n# V_auc = np.load('/kaggle/working/q_auc_arrhythmia.mat_20000_0.npy')\n# aor_count_train = np.load('/kaggle/working/count_arrhythmia.mat_train_ob20_normalized_20000_0.npy')\n# ss_s = np.load('/kaggle/working/subspace_scores_arrhythmia.mat_20000_0.npy')\n\n# #\n# #\n# #\n# d = len(aor_scores_train)\n# pos = np.arange(d)\n\n# plt.figure()\n# plt.plot(pos, aor_scores_train)\n# plt.grid()\n# plt.xlabel('Feature ranking')\n# plt.ylabel('AOR')\n# plt.title('Average Of Rewards')\n\n# #\n# # Plot AUC Train\n# #\n\n# auc = auc_train\n\n# a_dim = np.argmax(auc)\n# a_auc = auc[a_dim]\n# a_dim = a_dim+1\n\n# alpha0 = 0.5\n# alpha = alpha0 / d\n# print(f'alpha = {alpha}')\n# quality = auc - alpha * pos\n\n# q_dim = np.argmax(quality)\n# q_auc = auc[q_dim]\n# q_dim = q_dim+1\n\n# ss_dim = np.argmax(ss_s)\n\n# plt.figure()\n# plt.axis([0, d, np.min(auc), np.max(auc)*1.025])\n# plt.plot(pos, auc, color='b', linestyle='-', label = f'AUC ({a_dim},{a_auc:.3f})')\n# plt.plot(pos, quality, color='r', linestyle='--', label = f'Quality ({q_dim},{q_auc:.3f})')\n# plt.plot(pos, V_auc, color='g', linestyle='-', label = 'AUC_V')\n# plt.plot(q_dim-1,q_auc,'ro', a_dim-1, a_auc,'b^')\n# plt.legend(loc = 'lower right')\n# plt.grid()\n# plt.xlabel('Feature ranking')\n# plt.title('AUC & Quality: Training set')\n\n# print(f'Best according to AUC: dim = {a_dim} ({a_dim/d*100:.2f}%), AUC = {a_auc:.5f}')\n# print(f'Best according to Quality: dim = {q_dim} ({q_dim/d*100:.2f}%), AUC = {q_auc:.5f}')\n\n# #\n# #\n# #\n\n# auc = auc_test\n\n# a_dim = np.argmax(auc)\n# a_auc = auc[a_dim]\n# a_dim = a_dim+1\n\n# alpha0 = 0.5\n# alpha = alpha0 / d\n# print(f'alpha = {alpha}')\n# quality = auc - alpha * pos\n\n# q_dim = np.argmax(quality)\n# q_auc = auc[q_dim]\n# q_dim = q_dim+1\n\n# plt.figure()\n# plt.axis([0, d, np.min(auc), np.max(auc)*1.025])\n# plt.plot(pos, auc, color='b', linestyle='-', label = f'AUC ({a_dim},{a_auc:.3f})')\n# plt.plot(pos, quality, color='r', linestyle='--', label = f'Quality ({q_dim},{q_auc:.3f})')\n# plt.plot(pos, V_auc, color='g', linestyle='-', label = 'AUC_V')\n# plt.plot(q_dim-1,q_auc,'ro', a_dim-1, a_auc,'b^')\n# plt.legend(loc = 'lower right')\n# plt.grid()\n# plt.xlabel('Feature ranking')\n# plt.title('AUC & Quality: Test set')\n\n# print(f'Best according to AUC: dim = {a_dim} ({a_dim/d*100:.2f}%), AUC = {a_auc:.5f}')\n# print(f'Best according to Quality: dim = {q_dim} ({q_dim/d*100:.2f}%), AUC = {q_auc:.5f}')\n\n# #\n# #\n# #\n\n# plt.figure()\n# plt.plot(pos, aor_count_train)\n# plt.xlabel('Feature ranking')\n# #plt.ylabel('Feature ranking')\n# plt.title('Feature count')\n\n\n# #plt.figure()\n# #plt.plot(pos, V_f)\n# #plt.title('Value Function')\n# #plt.xlabel('Feature ranking')\n# ##plt.ylabel('')\n# #plt.grid()\n\n# plt.figure()\n# plt.plot(pos, ss_s, label = f'AUC ({ss_dim},{ss_s[ss_dim]:.3f})')\n# plt.title('Subspace score')\n# plt.xlabel('Feature ranking')\n# #plt.ylabel('')\n# plt.grid()\n# plt.legend(loc = 'lower right')\n\n\n\n# #mean(Q_f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T13:29:18.026127Z","iopub.execute_input":"2025-06-03T13:29:18.026336Z","iopub.status.idle":"2025-06-03T13:29:18.038264Z","shell.execute_reply.started":"2025-06-03T13:29:18.026320Z","shell.execute_reply":"2025-06-03T13:29:18.037524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print([f\"{aucsd:.3f}\" for aucsd in all_aucs])\n# print(np.max(all_aucs))\n# print(np.argmax(all_aucs))\n\n# print(ss_s)\n# print(aor_scores_train)\n# ids = np.argsort(ranking_train)\n# print(ranking_train)\n# print(f\"INFORMATIVE FEATURES: {ranking_train[ids][important_mask==1]}\")\n# print(f\"INFORMATIVE FEATURE AOR: {aor_scores_train[ids][important_mask==1]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T13:29:18.039008Z","iopub.execute_input":"2025-06-03T13:29:18.039335Z","iopub.status.idle":"2025-06-03T13:29:18.050539Z","shell.execute_reply.started":"2025-06-03T13:29:18.039307Z","shell.execute_reply":"2025-06-03T13:29:18.049969Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n\n# def aggregate_results(datasets, steps, runs, base_dir=\"dir\"):\n    \n#     result_dict = {}\n\n#     for dataset in datasets:\n#         all_auc = []\n#         all_auc_train = []\n#         all_aor = []\n#         all_count = []\n#         all_rankings = []\n\n#         for r in range(runs):\n#             auc_path = f\"auc_curve_{dataset}_{steps}_{r}.npy\"\n#             auc_train_path = f\"auc_curve_train_{dataset}_{steps}_{r}.npy\"\n#             aor_path = f\"ranking_{dataset}_train_ob20_normalized_{steps}_{r}.npy\"\n#             count_path = f\"count_{dataset}_train_ob20_normalized_{steps}_{r}.npy\"\n#             rank_path = f\"ranked_features_{dataset}_train_ob20_normalized_{steps}_{r}.npy\"\n\n#             all_auc.append(np.load(auc_path))\n#             all_auc_train.append(np.load(auc_train_path))\n#             all_aor.append(np.load(aor_path))\n#             all_count.append(np.load(count_path))\n#             all_rankings.append(np.load(rank_path))\n\n        \n#         all_auc = np.array(all_auc)\n#         all_auc_train = np.array(all_auc_train)\n#         all_aor = np.array(all_aor)\n#         all_count = np.array(all_count)\n#         all_rankings = np.array(all_rankings)\n\n#         mean_auc = np.mean(all_auc, axis=0)\n#         std_auc = np.std(all_auc, axis=0)\n\n#         mean_auc_train = np.mean(all_auc_train, axis=0)\n#         std_auc_train = np.std(all_auc_train, axis=0)\n\n#         mean_aor = np.mean(all_aor, axis=0)\n#         std_aor = np.std(all_aor, axis=0)\n\n#         mean_count = np.mean(all_count, axis=0)\n#         std_count = np.std(all_count, axis=0)\n\n#         ranking_scores = np.zeros_like(all_rankings[0], dtype=np.float32)\n#         for r in range(all_rankings.shape[0]):\n#             ranking_scores += np.argsort(np.argsort(all_rankings[r]))\n#         ranking_scores /= all_rankings.shape[0]\n#         mean_ranking = np.argsort(ranking_scores)\n\n#         result_dict[dataset] = {\n#             \"mean_auc\": mean_auc,\n#             \"std_auc\": std_auc,\n#             \"mean_auc_train\": mean_auc_train,\n#             \"std_auc_train\": std_auc_train,\n#             \"mean_aor\": mean_aor,\n#             \"std_aor\": std_aor,\n#             \"mean_count\": mean_count,\n#             \"std_count\": std_count,\n#             \"mean_ranking\": mean_ranking,\n#             \"rank_stability\": ranking_scores\n#         }\n\n#     return result_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T13:29:18.051284Z","iopub.execute_input":"2025-06-03T13:29:18.051957Z","iopub.status.idle":"2025-06-03T13:29:18.062915Z","shell.execute_reply.started":"2025-06-03T13:29:18.051940Z","shell.execute_reply":"2025-06-03T13:29:18.062224Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#import shutil\n#shutil.make_archive('/kaggle/working/output', 'zip', '/kaggle/working')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T13:29:18.063744Z","iopub.execute_input":"2025-06-03T13:29:18.063945Z","iopub.status.idle":"2025-06-03T13:29:18.074756Z","shell.execute_reply.started":"2025-06-03T13:29:18.063926Z","shell.execute_reply":"2025-06-03T13:29:18.074183Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}